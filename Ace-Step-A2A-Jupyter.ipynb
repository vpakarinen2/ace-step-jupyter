{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47c7ef-9cd7-4d8b-9ca5-9f5594e0ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y typing-extensions typing-inspection starlette pydantic grpcio fastapi ipython torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e73661-f8f5-4727-bbdb-ffec339e8cfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip setuptools wheel\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d30909-be69-42a7-9b0d-883e7ae08946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "BASE_DIR = \"/workspace\"\n",
    "\n",
    "A2A_REPAINT_DIR = os.path.join(BASE_DIR, \"text2audio_gen\", \"repaints\")\n",
    "T2A_INPUT_DIR = os.path.join(BASE_DIR, \"text2audio_input\")\n",
    "A2A_DIR = os.path.join(BASE_DIR, \"audio2audio_clips\")\n",
    "GEN_DIR = os.path.join(BASE_DIR, \"text2audio_gen\")\n",
    "\n",
    "for d in (A2A_DIR, T2A_INPUT_DIR, GEN_DIR, A2A_REPAINT_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "SRC_AUDIO_PATH = os.getenv(\"ACE_SRC_AUDIO\", \"/workspace/audio2audio_clips/src_audio.wav\")\n",
    "\n",
    "OUTPUT_WAV_PATH = os.path.join(GEN_DIR, \"generated_music.wav\")\n",
    "PROMPT_FILE = os.path.join(T2A_INPUT_DIR, \"prompt_input.txt\")\n",
    "LYRICS_FILE = os.path.join(T2A_INPUT_DIR, \"lyrics_input.txt\")\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "REPAINT_WAV_PATH = os.path.join(GEN_DIR, f\"repaint_{ts}.wav\")\n",
    "EXTEND_WAV_PATH  = os.path.join(GEN_DIR, f\"extend_{ts}.wav\")\n",
    "\n",
    "print(\"SRC_AUDIO_PATH:\", SRC_AUDIO_PATH)\n",
    "print(\"T2A_INPUT_DIR:\", T2A_INPUT_DIR)\n",
    "print(\"PROMPT_FILE  :\", PROMPT_FILE)\n",
    "print(\"LYRICS_FILE  :\", LYRICS_FILE)\n",
    "print(\"GEN_DIR:\", GEN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb0025-1d39-401c-b107-56a13de85414",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ace-step/ACE-Step.git\n",
    "%cd ACE-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ddfb8-b937-4fc1-960c-240deaed99b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9458df4-ce89-4a64-bbe1-26e86a217746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "repo_path = os.getenv('ACE_STEP_REPO_PATH', os.getcwd())\n",
    "os.chdir(repo_path)\n",
    "\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"In sys.path:\", repo_path in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65416ce8-6c19-4823-80fe-e75134ddc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = \"ACE-Step/ACE-Step-v1-3.5B\"\n",
    "cache_root = os.getenv('ACE_STEP_WEIGHTS_PATH', os.path.join(repo_path, '..', 'acestep_checkpoints'))\n",
    "os.makedirs(cache_root, exist_ok=True)\n",
    "\n",
    "snapshot_dir = snapshot_download(repo_id=repo_id, cache_dir=cache_root)\n",
    "print(\"Snapshot directory:\", snapshot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1109c-8747-4f34-9436-4d71f7dfc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from acestep.pipeline_ace_step import ACEStepPipeline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device_id = 0 if use_cuda else -1\n",
    "use_bf16 = True\n",
    "\n",
    "dtype = torch.bfloat16 if (use_bf16 and use_cuda) else torch.float32\n",
    "\n",
    "pipe = ACEStepPipeline(\n",
    "    checkpoint_dir=snapshot_dir,\n",
    "    dtype=dtype,      \n",
    "    device_id=device_id,           \n",
    "    torch_compile=False\n",
    ")\n",
    "\n",
    "pipe.load_checkpoint(checkpoint_dir=snapshot_dir)\n",
    "print(\"Pipeline loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e687b04-d62b-4cf6-bae0-759543b95894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(text_prompt: str, duration: int = 30):\n",
    "    waveform = model.generate(text=text_prompt, duration=duration)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a237af2-1305-42c0-9bd6-fe8860d0489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read(path: str) -> str:\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[warn] Missing {path}; creating starter file\")\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")\n",
    "        return \"\"\n",
    "    except UnicodeDecodeError:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read().strip()\n",
    "\n",
    "prompt_text = _read(PROMPT_FILE)\n",
    "lyrics_text = _read(LYRICS_FILE)\n",
    "\n",
    "print(\"Prompt chars:\", len(prompt_text))\n",
    "print(\"Lyrics chars:\", len(lyrics_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510499bd-f862-4301-a29f-1b6fe22ff637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, torch, torchaudio\n",
    "\n",
    "SR = 44100\n",
    "HOP = 4096  \n",
    "\n",
    "def sec_to_frames(s): \n",
    "    return int(round((s * SR) / HOP))\n",
    "\n",
    "def frames_to_sec(f):\n",
    "    return (f * HOP) / SR\n",
    "\n",
    "wav, sr = torchaudio.load(SRC_AUDIO_PATH)  \n",
    "if wav.dim() == 2 and wav.size(0) > 1:\n",
    "    wav = wav.mean(dim=0, keepdim=True)\n",
    "if sr != SR:\n",
    "    wav = torchaudio.functional.resample(wav, sr, SR)\n",
    "    sr = SR\n",
    "L = wav.shape[-1]\n",
    "total_frames = math.ceil(L / HOP)           \n",
    "duration_qs  = frames_to_sec(total_frames)  \n",
    "\n",
    "desired_start_s = 5.0\n",
    "desired_span_s  = 10.0\n",
    "\n",
    "start_f = max(0, min(total_frames - 2, sec_to_frames(desired_start_s)))\n",
    "end_f   = min(total_frames, start_f + max(2, sec_to_frames(desired_span_s)))\n",
    "start_s_q = frames_to_sec(start_f)\n",
    "end_s_q   = frames_to_sec(end_f)\n",
    "\n",
    "print(\"Source duration (q):\", duration_qs, \"s | repaint window:\", start_s_q, \"->\", end_s_q, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781fa642-ab50-4e52-9923-a0372bcb792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe(\n",
    "    audio_duration=10,\n",
    "    prompt=prompt_text,\n",
    "    lyrics=lyrics_text,\n",
    "    infer_step=60,\n",
    "    guidance_scale=15.0,\n",
    "    scheduler_type=\"euler\",\n",
    "    cfg_type=\"apg\",\n",
    "    omega_scale=10.0,\n",
    "    manual_seeds=\"\",\n",
    "    guidance_interval=0.5,\n",
    "    guidance_interval_decay=0.0,\n",
    "    min_guidance_scale=3.0,\n",
    "    use_erg_tag=True,\n",
    "    use_erg_lyric=True,\n",
    "    use_erg_diffusion=True,\n",
    "    oss_steps=\"\",\n",
    "    guidance_scale_text=0.0,\n",
    "    guidance_scale_lyric=0.0,\n",
    "    src_audio_path=SRC_AUDIO_PATH,\n",
    "    save_path=REPAINT_WAV_PATH,\n",
    "    # Repaint\n",
    "    task=\"repaint\",\n",
    "    audio2audio_enable=True,                   \n",
    "    ref_audio_strength=0.4,  \n",
    "    retake_variance=0.6,\n",
    "    repaint_start=start_s_q,\n",
    "    repaint_end=end_s_q,\n",
    "    retake_seeds=\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
